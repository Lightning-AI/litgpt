name: GPU tests

trigger:
  branches:
    include:
      - "main"
      - "wip"

pr:
  branches:
    include:
      - "main"
      - "wip"

jobs:
  - job: testing
    strategy:
      matrix:
        "ordinary":
          image: "pytorchlightning/pytorch_lightning:base-cuda-py3.10-torch2.2-cuda12.1.0"
          dependency: ""
        "w. Thunder":
          image: "pytorchlightning/pytorch_lightning:base-cuda-py3.10-torch2.2-cuda12.1.0"
          dependency: "compiler"
    variables:
      DEVICES: $( python -c 'print("$(Agent.Name)".split("_")[-1])' )
      PL_RUN_CUDA_TESTS: "1"
      TRANSFORMERS_CACHE: "/var/tmp/hf/transformers"
      HF_HOME: "/var/tmp/hf/home"
      HF_HUB_CACHE: "/var/tmp/hf/hub"
      CI: "true"
    container:
      image: $(image)
      options: "--gpus=all --shm-size=8gb -v /var/tmp:/var/tmp"
    workspace:
      clean: all
    pool: "lit-rtx-3090"
    timeoutInMinutes: "35"
    cancelTimeoutInMinutes: "2"
    steps:
      - bash: |
          echo "##vso[task.setvariable variable=CUDA_VISIBLE_DEVICES]$(DEVICES)"
        displayName: "set env. vars"

      - bash: |
          echo $(DEVICES)
          echo $CUDA_VISIBLE_DEVICES
          whereis nvidia
          nvidia-smi
          which python && which pip
          python --version
          pip --version
          pip list
        displayName: "Image info & NVIDIA"

      - script: |
          pip install --upgrade pip
          pip install '.[extra,test]' -U
        displayName: "Install dependencies"

      - script: |
          set -e
          pip uninstall -y torchvision torchaudio
          pip install --pre 'nvfuser-cu121[torch]' --extra-index-url https://pypi.nvidia.com
          pip install '.[compiler]'
          python -c "from thunder.executors import nvfuser_available ; assert nvfuser_available(), 'nvFuser is missing!'"
          python -c "from thunder.executors.triton_utils import triton_version ; assert triton_version() is not None, 'triton is missing!'"
        condition: eq(variables['dependency'], 'compiler')
        displayName: "Install nvFuser & Thunder"

      - bash: |
          set -e
          pip list
          python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu == 2, f'GPU: {mgpu}'"
        displayName: "Env details"

      - bash: |
          pytest -v --disable-pytest-warnings --strict-markers --color=yes \
            --ignore-glob="tests/test_thunder*" \
            --ignore="tests/test_unsloth_executor.py"
        displayName: "Ordinary tests"
        condition: ne(variables['dependency'], 'compiler')
        timeoutInMinutes: "5"

    - bash: |
        pytest -v \
          --ignore-glob="tests/test_thunder*" \
          --ignore="tests/test_unsloth_executor.py"
      displayName: 'Ordinary tests'
      condition: ne(variables['dependency'], 'compiler')
      timeoutInMinutes: "5"

    - bash: |
        # install thunder from source, so that, thunder.tests will be available
        pip install -U "thunder[test] @ git+https://github.com/Lightning-AI/lightning-thunder.git"
        PL_RUN_CUDA_TESTS=0 pytest tests/ext_thunder/test_thunder_networks.py -v # without env var, it filters out all tests
      displayName: 'Extra tests w. Thunder [main branch]'
      condition: eq(variables['dependency'], 'compiler')
      env:
        PL_RUN_CUDA_TESTS: "0"
      timeoutInMinutes: "10"

    - bash: |
        pytest -v
      displayName: 'All tests'
      condition: eq(variables['dependency'], 'compiler')
      timeoutInMinutes: "5"

    - bash: |
        wget https://raw.githubusercontent.com/Lightning-AI/utilities/main/scripts/run_standalone_tests.sh
        bash run_standalone_tests.sh "tests"
      displayName: "Standalone tests"
      env:
        PL_RUN_STANDALONE_TESTS: "1"
        # NUM_PARALLEL_TESTS: "10"
      timeoutInMinutes: "10"
