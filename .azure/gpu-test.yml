name: GPU tests

trigger:
  branches:
    include:
      - "main"
      - "wip"

pr:
  branches:
    include:
      - "main"
      - "wip"

jobs:
  - job: testing
    strategy:
      matrix:
        "ordinary":
          #image: "pytorchlightning/pytorch_lightning:base-cuda-py3.10-torch2.7-cuda12.6.3"
          dependency: ""
        "w. Thunder":
          #image: "pytorchlightning/pytorch_lightning:base-cuda-py3.10-torch2.7-cuda12.6.3"
          dependency: "compiler"
    variables:
      DEVICES: $( python -c 'print("$(Agent.Name)".split("_")[-1])' )
      PL_RUN_CUDA_TESTS: "1"
      TRANSFORMERS_CACHE: "/var/tmp/hf/transformers"
      HF_HOME: "/var/tmp/hf/home"
      HF_HUB_CACHE: "/var/tmp/hf/hub"
      CI: "true"
      PYTHON_VERSION: "3.10"
      CUDA_VERSION: "12.6.3"
      TORCH_VERSION: "2.7"
    container:
      image: "pytorchlightning/pytorch_lightning:base-cuda-py$(PYTHON_VERSION)-torch$(TORCH_VERSION)-cuda$(CUDA_VERSION)"
      options: "--gpus=all --shm-size=8gb -v /var/tmp:/var/tmp"
    workspace:
      clean: all
    pool: "lit-rtx-3090"
    timeoutInMinutes: "35"
    cancelTimeoutInMinutes: "2"
    steps:
      - bash: |
          echo "##vso[task.setvariable variable=CUDA_VISIBLE_DEVICES]$(DEVICES)"
        displayName: "set env. vars"

      - bash: |
          echo $(DEVICES)
          echo $CUDA_VISIBLE_DEVICES
          whereis nvidia
          nvidia-smi
          which python && which pip
          python --version
          pip --version
          pip list
        displayName: "Image info & NVIDIA"

      - script: |
          pip install --upgrade pip
          pip install '.[extra,test]' -U
        displayName: "Install dependencies"

      - script: |
          set -e
          CUDA_VERSION_MM=${CUDA_VERSION%.*}
          pip uninstall -y torchvision torchaudio
          pip install '.[compiler]' --extra-index-url https://pypi.nvidia.com/ -U "nvfuser-cu${CUDA_VERSION_MM/./}-torch${TORCH_VERSION/./}"
          python -c "from thunder.executors import nvfuser_available ; assert nvfuser_available(), 'nvFuser is missing!'"
          python -c "from thunder.executors.triton_utils import triton_version ; assert triton_version() is not None, 'triton is missing!'"
        condition: eq(variables['dependency'], 'compiler')
        displayName: "Install nvFuser & Thunder"

      - bash: |
          set -e
          pip list
          python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu == 2, f'GPU: {mgpu}'"
          python -c "from torch import __version__ as ver ; assert '.'.join(str(ver).split('.')[:2]) == '$(TORCH_VERSION)', f'PyTorch: installed {ver} but expected $(TORCH_VERSION)'"
        displayName: "Env details"

      - bash: |
          pytest -v \
            --ignore-glob="tests/test_thunder*" \
            --ignore="tests/test_unsloth_executor.py"
        displayName: "Ordinary tests"
        condition: ne(variables['dependency'], 'compiler')
        timeoutInMinutes: "5"

      - bash: |
          # install thunder from source, so that, thunder.tests will be available
          pip install -U "lightning-thunder[test] @ git+https://github.com/Lightning-AI/lightning-thunder.git"
          PL_RUN_CUDA_TESTS=0 pytest tests/ext_thunder/test_thunder_networks.py -v # without env var, it filters out all tests
        displayName: "Extra tests w. Thunder [main branch]"
        condition: eq(variables['dependency'], 'compiler')
        env:
          PL_RUN_CUDA_TESTS: "0"
          TORCHDYNAMO_VERBOSE: "1"
        timeoutInMinutes: "10"

      - bash: |
          pytest -v
        displayName: "All tests"
        condition: eq(variables['dependency'], 'compiler')
        timeoutInMinutes: "5"

      - bash: |
          wget https://raw.githubusercontent.com/Lightning-AI/utilities/main/scripts/run_standalone_tests.sh
          bash run_standalone_tests.sh "tests"
        displayName: "Standalone tests"
        env:
          PL_RUN_STANDALONE_TESTS: "1"
          # NUM_PARALLEL_TESTS: "10"
        timeoutInMinutes: "10"
