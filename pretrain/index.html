
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../prepare_dataset/">
      
      
        <link rel="next" href="../pretrain_tinyllama/">
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Pretrain LLMs with LitGPT - LitGPT Tutorials</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/mkdocs_pagetree_plugin.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pretrain-llms-with-litgpt" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="LitGPT Tutorials" class="md-header__button md-logo" aria-label="LitGPT Tutorials" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LitGPT Tutorials
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Pretrain LLMs with LitGPT
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="LitGPT Tutorials" class="md-nav__button md-logo" aria-label="LitGPT Tutorials" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LitGPT Tutorials
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../0_to_litgpt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Zero to LitGPT: Getting Started with Pretraining, Finetuning, and Using LLMs
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../convert_hf_checkpoint/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Converting Hugging Face Transformers to LitGPT weights
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../convert_lit_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Convert lit models
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Serve and Deploy LLMs
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../download_model_weights/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Download Model Weights with LitGPT
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LLM Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Finetuning
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune_adapter/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Finetuning with Adapter
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune_full/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Finetuning the whole model
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune_lora/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Finetuning with LoRA / QLoRA
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Inference
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../oom/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Oom
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../prepare_dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Preparing Datasets
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Pretrain LLMs with LitGPT
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Pretrain LLMs with LitGPT
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#using-the-litgpt-pretrain-command" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using the litgpt pretrain command
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pretrain-on-custom-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pretrain on custom data
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#continued-pretraining-on-custom-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Continued pretraining on custom data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Continued pretraining on custom data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-continued-pretraining-when-starting-from-a-downloaded-base-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        1) Continued pretraining when starting from a downloaded base model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-continued-pretraining-after-interruption" class="md-nav__link">
    <span class="md-ellipsis">
      
        2) Continued pretraining after interruption
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-continued-pretraining-on-a-new-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        3) Continued pretraining on a new dataset
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pretrain-a-11b-tinyllama-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pretrain a 1.1B TinyLlama model
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimize-litgpt-pretraining-with-lightning-thunder" class="md-nav__link">
    <span class="md-ellipsis">
      
        Optimize LitGPT pretraining with Lightning Thunder
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#project-templates" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project templates
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../pretrain_tinyllama/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Pretrain TinyLlama
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../python-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LitGPT Python API
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../quantize/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quantize the model
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../resource-tables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Resource Tables
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_20" >
        
          
          <label class="md-nav__link" for="__nav_20" id="__nav_20_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Developer docs
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_20_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_20">
            <span class="md-nav__icon md-icon"></span>
            
  
    Developer docs
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer-docs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Index
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer-docs/adding-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adding New Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer-docs/python-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LitGPT High-level Python API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21" >
        
          
          <label class="md-nav__link" for="__nav_21" id="__nav_21_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_21_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21">
            <span class="md-nav__icon md-icon"></span>
            
  
    Examples
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_1" >
        
          
          <label class="md-nav__link" for="__nav_21_1" id="__nav_21_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Ptl trainer
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Ptl trainer
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/ptl-trainer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Index
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#using-the-litgpt-pretrain-command" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using the litgpt pretrain command
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pretrain-on-custom-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pretrain on custom data
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#continued-pretraining-on-custom-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Continued pretraining on custom data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Continued pretraining on custom data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-continued-pretraining-when-starting-from-a-downloaded-base-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        1) Continued pretraining when starting from a downloaded base model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-continued-pretraining-after-interruption" class="md-nav__link">
    <span class="md-ellipsis">
      
        2) Continued pretraining after interruption
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-continued-pretraining-on-a-new-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        3) Continued pretraining on a new dataset
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pretrain-a-11b-tinyllama-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pretrain a 1.1B TinyLlama model
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimize-litgpt-pretraining-with-lightning-thunder" class="md-nav__link">
    <span class="md-ellipsis">
      
        Optimize LitGPT pretraining with Lightning Thunder
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#project-templates" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project templates
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="pretrain-llms-with-litgpt">Pretrain LLMs with LitGPT</h1>
<p>This document explains how to pretrain LLMs using LitGPT.</p>
<p>&nbsp;</p>
<h2 id="using-the-litgpt-pretrain-command">Using the <code>litgpt pretrain</code> command</h2>
<p>You can pretrain models in LitGPT using the <code>litgpt pretrain</code> API starting with any of the available architectures listed by calling <code>litgpt pretrain list</code> without any additional arguments:</p>
<p>&nbsp;</p>
<blockquote>
<p>[!TIP]
To install all required dependencies before pretraining, first run <code>pip install "litgpt[all]"</code>.
&nbsp;</p>
</blockquote>
<pre><code class="language-bash">litgpt pretrain list
</code></pre>
<p>Shown below is an abbreviated list:</p>
<pre><code>ValueError: Please specify --model_name &lt;model_name&gt;. Available values:
Camel-Platypus2-13B
...
Gemma-2b
...
Llama-2-7b-hf
...
Mixtral-8x7B-v0.1
...
pythia-14m
</code></pre>
<p>For demonstration purposes, we can pretrain a small 14 million-parameter Pythia model on the small TinyStories dataset using the <a href="https://github.com/Lightning-AI/litgpt/blob/main/config_hub/pretrain/debug.yaml">debug.yaml config file</a> as follows:</p>
<pre><code class="language-bash">litgpt pretrain pythia-14m \
   --config https://raw.githubusercontent.com/Lightning-AI/litgpt/main/config_hub/pretrain/debug.yaml
</code></pre>
<p>&nbsp;</p>
<h2 id="pretrain-on-custom-data">Pretrain on custom data</h2>
<p>The simplest way to get started with pretraining on a small custom dataset is by using the <code>TextFiles</code> data module, which lets you pretrain a dataset from a folder containing plain text files.</p>
<p>&nbsp;</p>
<blockquote>
<p>[!NOTE]
This approach adds a beginning-of-sequence token at the beginning of each text file. However, it otherwise assumes that you have already cleaned the text files, for example, removing any unwanted characters and inserting beginning-of-sequence and end-of-sequence tokens if applicable in case a text file conists of multiple documents.</p>
</blockquote>
<p>&nbsp;</p>
<blockquote>
<p>[!WARNING]
Using this approach is only recommended for small datasets. Since text data is highly compressible, it is often stored in compressed format, and often in file formats where documents can be loaded row by row without having to load entire files at once. In other words, this <code>TextFiles</code> approach is only feasible to store the data in plain text files due to the limited size.
For datasets that take up multiple gigabytes, we recommend preprocessing it with <a href="https://github.com/Lightning-AI/litdata">LitData</a> and then reading it from a local directory or S3 connection using <code>--data LitData</code>.</p>
</blockquote>
<p>&nbsp;</p>
<p>For instance, assume you stored a number of text files in a <code>custom_pretraining_dataset</code> folder (we recommend avoiding small files and concatenating them to files of at least 50 Mb for efficiency):</p>
<pre><code class="language-bash">~ ls -lh custom_pretraining_data
total 3225M
-rw-r--r-- 1 sebastian 50M Apr  2 18:31 combined_1.txt
-rw-r--r-- 1 sebastian 50M Apr  2 18:31 combined_2.txt
-rw-r--r-- 1 sebastian 50M Apr  2 18:31 combined_3.txt
-rw-r--r-- 1 sebastian 50M Apr  2 18:31 combined_4.txt
-rw-r--r-- 1 sebastian 50M Apr  2 18:31 combined_5.txt
...
</code></pre>
<p>You can then use the <code>TextFiles</code> API to pretrain a model (here a small <code>pythia-14m</code> model for illustration purposes) from scratch as follows:</p>
<pre><code class="language-bash">litgpt download EleutherAI/pythia-14m \
  --tokenizer_only true

litgpt pretrain pythia-14m \
   --tokenizer_dir EleutherAI/pythia-14m \
   --data TextFiles \
   --data.train_data_path custom_pretraining_data \
   --train.lr_warmup_steps=200 \
   --optimizer AdamW \
   --optimizer.lr 0.005
</code></pre>
<p>&nbsp;</p>
<blockquote>
<p>[!TIP]
Use the <code>litgpt pretrain --data.help TextFiles</code> command to list additional dataset options.
&nbsp;</p>
</blockquote>
<p>&nbsp;</p>
<h2 id="continued-pretraining-on-custom-data">Continued pretraining on custom data</h2>
<p>Often, it makes sense to adopt an existing pretrained model and further pretrain it on our own custom data. The existing pretrained model can be either our own pretrained model or a model downloaded from a model hub.</p>
<p>The following subsections illustrate three typical scenarioes:</p>
<ol>
<li>Starting from a downloaded base model</li>
<li>Continuing the pretraining after interruption</li>
<li>Further pretraining on a different dataset</li>
</ol>
<p>&nbsp;</p>
<blockquote>
<p>[!NOTE]
This approach assumes that you have already cleaned the text files, for example, removing any unwanted characters and inserting beginning-of-sequence and end-of-sequence tokens if applicable.</p>
</blockquote>
<p>&nbsp;</p>
<blockquote>
<p>[!WARNING]
Using this approach is only recommended for small datasets. Since text data is highly compressible, it is often stored in compressed format, and often in file formats where documents can be loaded row by row without having to load entire files at once. In other words, this <code>TextFiles</code> approach is only feasible to store the data in plain text files due to the limited size.
For datasets that take up multiple gigabytes, we recommend preprocessing it with <a href="https://github.com/Lightning-AI/litdata">LitData</a> and then reading it from a local directory or S3 connection using <code>--data LitData --data.path path/to/your/data</code>.</p>
</blockquote>
<p>&nbsp;</p>
<h3 id="1-continued-pretraining-when-starting-from-a-downloaded-base-model">1) Continued pretraining when starting from a downloaded base model</h3>
<p>For instance, let's assume we download a Pythia model:</p>
<pre><code class="language-bash">litgpt download EleutherAI/pythia-160m
</code></pre>
<p>Next, assume we have a custom dataset stored in text files similar to the <em>Pretrain on custom data</em> above. We can further pretrain the Pythia model via the <code>--initial_checkpoint_dir</code> setting as follows:</p>
<pre><code class="language-bash">litgpt pretrain pythia-160m \
   --initial_checkpoint_dir EleutherAI/pythia-160m \
   --tokenizer_dir EleutherAI/pythia-160m \
   --out_dir ./new_pretrained_checkpoint \
   --data TextFiles \
   --data.train_data_path custom_pretraining_data \
   --train.max_tokens 1_000_000
</code></pre>
<p>&nbsp;</p>
<blockquote>
<p>[!TIP]
Use the <code>litgpt pretrain --data.help TextFiles</code> command to list additional dataset options.</p>
</blockquote>
<p>&nbsp;</p>
<h3 id="2-continued-pretraining-after-interruption">2) Continued pretraining after interruption</h3>
<p>In case a you interrupted a training run, you can continue it with the <code>--resume</code> option, for example:</p>
<pre><code class="language-bash">litgpt pretrain pythia-160m \
   --resume &quot;auto&quot; \
   --tokenizer_dir EleutherAI/pythia-160m \
   --out_dir ./new_pretrained_checkpoint \
   --data TextFiles \
   --data.train_data_path custom_pretraining_data \
   --train.max_tokens 1_000_000
</code></pre>
<p>&nbsp;</p>
<h3 id="3-continued-pretraining-on-a-new-dataset">3) Continued pretraining on a new dataset</h3>
<p>Suppose you pretrained a model using the examples above. To further pretrain the model on a new dataset, you first need to convert the pretrained checkpoint via the following command:</p>
<pre><code class="language-bash">litgpt convert_pretrained_checkpoint ./new_pretrained_checkpoint/final ./new_pretrained_checkpoint_converted
</code></pre>
<p>Then, you can pretrain the converted model on the new dataset as follows:</p>
<pre><code class="language-bash">litgpt pretrain pythia-160m \
   --initial_checkpoint_dir ./new_pretrained_checkpoint_converted \
   --tokenizer_dir EleutherAI/pythia-160m \
   --out_dir ./new_pretrained_checkpoint_2 \
   --data TextFiles \
   --data.train_data_path custom_pretraining_data_2 \
   --train.max_tokens 1_000_000
</code></pre>
<p>&nbsp;</p>
<h2 id="pretrain-a-11b-tinyllama-model">Pretrain a 1.1B TinyLlama model</h2>
<p>You can find an end-to-end LitGPT tutorial for pretraining a TinyLlama model using LitGPT <a href="../pretrain_tinyllama/">here</a>.</p>
<p>&nbsp;</p>
<h2 id="optimize-litgpt-pretraining-with-lightning-thunder">Optimize LitGPT pretraining with Lightning Thunder</h2>
<p><a href="https://github.com/Lightning-AI/lightning-thunder">Lightning Thunder</a> is a source-to-source compiler for PyTorch, which is fully compatible with LitGPT. In experiments, Thunder resulted in a 40% speed-up compared to using regular PyTorch when finetuning a 7B Llama 2 model.</p>
<p>For more information, see the <a href="https://github.com/Lightning-AI/lightning-thunder">Lightning Thunder extension README</a>.</p>
<p>&nbsp;</p>
<h2 id="project-templates">Project templates</h2>
<p>The following <a href="https://lightning.ai/lightning-ai/studios">Lightning Studio</a> templates provide LitGPT pretraining projects in reproducible environments with multi-GPU and multi-node support:
&nbsp;</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><p align="left"><a href="https://lightning.ai/lightning-ai/studios/prepare-the-tinyllama-1t-token-dataset">Prepare the TinyLlama 1T token dataset</a> <br> <a href="https://lightning.ai/lightning-ai/studios/prepare-the-tinyllama-1t-token-dataset"><img src="https://pl-public-data.s3.amazonaws.com/assets_litgpt/readme/3.webp" width="300"></p></a></td>
<td><a href="https://lightning.ai/lightning-ai/studios/pretrain-llms-tinyllama-1-1b">Pretrain LLMs - TinyLlama 1.1B</a> <br> <p align="left"><a href="https://lightning.ai/lightning-ai/studios/pretrain-llms-tinyllama-1-1b"><img src="https://pl-public-data.s3.amazonaws.com/assets_litgpt/readme/4.webp" width="300"></p></a></td>
</tr>
<tr>
<td><a href="https://lightning.ai/lightning-ai/studios/continued-pretraining-with-tinyllama-1-1b">Continued Pretraining with TinyLlama 1.1B</a> <br> <p align="left"><a href="https://lightning.ai/lightning-ai/studios/continued-pretraining-with-tinyllama-1-1b"><img src="https://pl-public-data.s3.amazonaws.com/assets_litgpt/readme/1.webp" width="300"></p></a></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": [], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../assets/mkdocs_pagetree_plugin.js"></script>
      
    
  </body>
</html>