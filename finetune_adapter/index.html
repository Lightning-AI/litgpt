
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../finetune/">
      
      
        <link rel="next" href="../finetune_full/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.21">
    
    
      
        <title>Finetuning with Adapter - LitGPT Tutorials</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.2a3383ac.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/mkdocs_pagetree_plugin.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#finetuning-with-adapter" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="LitGPT Tutorials" class="md-header__button md-logo" aria-label="LitGPT Tutorials" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LitGPT Tutorials
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Finetuning with Adapter
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="LitGPT Tutorials" class="md-nav__button md-logo" aria-label="LitGPT Tutorials" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LitGPT Tutorials
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../0_to_litgpt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Zero to LitGPT: Getting Started with Pretraining, Finetuning, and Using LLMs
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../convert_hf_checkpoint/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Converting Hugging Face Transformers to LitGPT weights
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../convert_lit_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Convert lit models
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Serve and Deploy LLMs
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../download_model_weights/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Download Model Weights with LitGPT
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM Evaluation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Finetuning
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Finetuning with Adapter
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Finetuning with Adapter
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Preparation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-the-finetuning" class="md-nav__link">
    <span class="md-ellipsis">
      Running the finetuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Running the finetuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#test-the-model" class="md-nav__link">
    <span class="md-ellipsis">
      Test the model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tune-on-your-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Tune on your dataset
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune_full/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Finetuning the whole model
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune_lora/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Finetuning with LoRA / QLoRA
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Inference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../oom/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Oom
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../prepare_dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Preparing Datasets
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../pretrain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pretrain LLMs with LitGPT
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../pretrain_tinyllama/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pretrain TinyLlama
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../python-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LitGPT Python API
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../quantize/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quantize the model
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../resource-tables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Resource Tables
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_20" >
        
          
          <label class="md-nav__link" for="__nav_20" id="__nav_20_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Developer docs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_20_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_20">
            <span class="md-nav__icon md-icon"></span>
            Developer docs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer-docs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Index
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer-docs/adding-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adding New Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer-docs/python-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LitGPT High-level Python API
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21" >
        
          
          <label class="md-nav__link" for="__nav_21" id="__nav_21_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_21_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_1" >
        
          
          <label class="md-nav__link" for="__nav_21_1" id="__nav_21_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ptl trainer
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_1">
            <span class="md-nav__icon md-icon"></span>
            Ptl trainer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/ptl-trainer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Index
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Preparation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-the-finetuning" class="md-nav__link">
    <span class="md-ellipsis">
      Running the finetuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Running the finetuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#test-the-model" class="md-nav__link">
    <span class="md-ellipsis">
      Test the model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tune-on-your-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Tune on your dataset
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="finetuning-with-adapter">Finetuning with Adapter</h1>
<p>Adapter, first introduced for the LLaMA model as <a href="https://arxiv.org/abs/2303.16199">LLaMA-Adapter</a>, is a form of prefix-tuning that prepends a learnable adaption-prompt to the inputs of the attention blocks in an LLM. In total, there are only ~500k parameters to update during finetuning in StableLM 3B, which significantly reduces the memory footprint and speeds up training.</p>
<p>We are able to demonstrate instruction-finetuning LitGPT StableLM 3B on the <a href="https://github.com/tatsu-lab/stanford_alpaca">Alpaca</a> dataset on a <strong>single RTX 3060 GPU</strong>. If using 8 GPUs, finetuning can be completed in under 1 hour.</p>
<p>If you are new to Adapter and are interested to learn more about how it works before proceeding with the finetuning guide below, you might find our article <a href="https://lightning.ai/pages/community/article/understanding-llama-adapters/">Understanding Parameter-Efficient Finetuning of Large Language Models: From Prefix Tuning to LLaMA-Adapters</a> helpful.</p>
<p>LLaMA-Adapter v2 extends the original LLaMA-Adapter idea by adding trainable bias and scale parameters to each linear layer in the transformer. Furthermore, LLaMA-Adapter v2 makes the normalization layers trainable. Where the StableLM 3B model has 500k trainable parameters with GPT v1, GPT-Adapter v2 adds an additional 1.5 M trainable parameter for the bias and scale parameters and ~300k trainable parameters for the normalization layers. So, adapter v2 has ~2.3 M trainable parameters in total.</p>
<h2 id="preparation">Preparation</h2>
<p>The steps here only need to be done once:</p>
<ol>
<li>Follow the instructions in the <a href="../README.md">README</a> to install the dependencies.</li>
<li>Download and convert the weights following our <a href="../download_model_weights/">guide</a>.</li>
</ol>
<p>LitGPT provides common datasets for finetuning, such as Alpaca, LIMA, Dolly, and more.
You can optionally <a href="#tune-on-your-dataset">prepare your own dataset</a>.
For more information about dataset preparation, also see the <a href="../prepare_dataset/">prepare_dataset.md</a> tutorial.</p>
<h2 id="running-the-finetuning">Running the finetuning</h2>
<pre><code class="language-bash">litgpt finetune_adapter stabilityai/stablelm-base-alpha-3b \
  --data Alpaca \
</code></pre>
<p>or for Adapter V2</p>
<pre><code class="language-bash">litgpt finetune adapter_v2 stabilityai/stablelm-base-alpha-3b \
  --data Alpaca \
</code></pre>
<p>The finetuning requires at least one GPU with ~12 GB memory.
You can speed up training by passing the <code>devices</code> argument to the script to utilize more GPUs if available.
Depending on the available GPU memory, you can also tune the <code>micro_batch_size</code> parameter to utilize the GPU efficiently.
To fit Adapter V2 to 12GB memory set <code>--train.micro_batch_size 2</code>.</p>
<p>For example, the following settings will let you finetune the model in under 1 hour:</p>
<pre><code class="language-bash">--devices 4 --train.micro_batch_size 4
</code></pre>
<p>This script will save checkpoints periodically to the <code>out_dir</code> directory. If you are finetuning different models or on your own dataset, you can specify an output directory with your preferred name:</p>
<pre><code class="language-bash">litgpt finetune_adapter stabilityai/stablelm-base-alpha-3b \
  --data Alpaca \
  --out_dir out/adapter/my-model-finetuned
</code></pre>
<p>or for Adapter V2</p>
<pre><code class="language-bash">litgpt finetune_adapter_v2 stabilityai/stablelm-base-alpha-3b \
  --data Alpaca \
  --out_dir out/adapter_v2/my-model-finetuned
</code></pre>
<p>If your GPU does not support <code>bfloat16</code>, you can pass the <code>--precision 32-true</code> argument.
For instance, to fine-tune on MPS (the GPU on modern Macs), you can run</p>
<pre><code class="language-bash">litgpt finetune_adapter stabilityai/stablelm-base-alpha-3b \
  --data Alpaca \
  --out_dir out/adapter/my-model-finetuned \
  --precision 32-true
</code></pre>
<p>Note that <code>mps</code> as the accelerator will be picked up automatically by Fabric when running on a modern Mac.</p>
<h3 id="quantization">Quantization</h3>
<p>Optionally, finetuning using quantization can be enabled via the <code>--quantize</code> flag, for example using the 4-bit NormalFloat data type:</p>
<pre><code class="language-bash">litgpt finetune_adapter stabilityai/stablelm-base-alpha-3b \
  --quantize &quot;bnb.nf4&quot;
</code></pre>
<p>or using <code>adapter_v2</code> with double-quantization:</p>
<pre><code class="language-bash">litgpt finetune_adapter_v2 stabilityai/stablelm-base-alpha-3b \
  --quantize &quot;bnb.nf4-dq&quot;
</code></pre>
<p>For additional benchmarks and resource requirements, please see the <a href="../resource-tables/">Resource Tables</a>.</p>
<h2 id="test-the-model">Test the model</h2>
<p>You can test the finetuned model with your own instructions by running:</p>
<pre><code class="language-bash">litgpt generate_adapter stabilityai/stablelm-base-alpha-3b \
    --prompt &quot;Recommend a movie to watch on the weekend.&quot;
</code></pre>
<p>or for Adapter V2</p>
<pre><code class="language-bash">litgpt generate_adapter_v2 stabilityai/stablelm-base-alpha-3b \
    --prompt &quot;Recommend a movie to watch on the weekend.&quot;

</code></pre>
<p>Output:</p>
<pre><code class="language-text">A good movie to watch on the weekend would be The Lion King, since it's a classic family film that everyone can enjoy...
</code></pre>
<p>If your GPU supports <code>bfloat16</code>, the script will automatically use it.</p>
<h2 id="tune-on-your-dataset">Tune on your dataset</h2>
<p>You can easily train on your own instruction dataset saved in JSON format.</p>
<ol>
<li>
<p>Create a JSON file in which each row holds one instruction-response pair.
   A row has an entry for 'instruction' and 'output', and optionally 'input'. Note that currently, the 'input' field is only used in the Alpaca chat template. If you are using the Alpaca template, 'input' can be the empty string if the instruction doesn't require a context.
   Below is an example json file:</p>
<p><code>text
[
    {
        "instruction": "Arrange the given numbers in ascending order.",
        "input": "2, 4, 0, 8, 3", // Optional: only used in Alpaca chat template
        "output": "0, 2, 3, 4, 8"
    },
    ...
]</code></p>
</li>
<li>
<p>Run <code>litgpt adapter</code> or <code>litgpt adapter_v2</code> by passing in the location of your data (and optionally other parameters):</p>
<p><code>bash
litgpt finetune_adapter tiiuae/falcon-7b \
    --data JSON \
    --data.json_path data/mydata.json \
    --out_dir data/mydata-finetuned</code></p>
</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../assets/mkdocs_pagetree_plugin.js"></script>
      
    
  </body>
</html>